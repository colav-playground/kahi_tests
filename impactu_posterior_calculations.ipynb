{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa181783-467f-433f-9d30-4d0ed329e464",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from pymongo import MongoClient\n",
    "import  numpy as np\n",
    "import datetime as dt\n",
    "from joblib import Parallel, delayed\n",
    "import os.path\n",
    "from bson import ObjectId\n",
    "from math import log, exp\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b41c606-69d2-4eed-8a5a-79a36e4c3fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "client=MongoClient()\n",
    "colombia=client[\"kahi_test\"]\n",
    "impactu=client[\"kahi_impactu\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3662c7ae-1313-4c6a-92c6-b60c7deacf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the list of institutions ids with works\n",
    "institutions_ids=[]\n",
    "for aff in colombia[\"affiliations\"].find({\"types.type\":{\"$nin\":[\"faculty\",\"department\",\"group\"]}}):\n",
    "    count=colombia[\"works\"].count_documents({\"authors.affiliations.id\":aff[\"_id\"]})\n",
    "    if count!=0:\n",
    "        institutions_ids.append(aff[\"_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1d1286f-0e49-4280-8d85-66afcb9bcbb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(institutions_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46c1c6bc-106d-429f-bd38-b30e5474bdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for idx in [ObjectId(\"637feec471459ce0bcb7a739\")]:\n",
    "def network_creation(idx):\n",
    "    already=impactu[\"affiliations\"].find_one({\"_id\":idx})\n",
    "    if already:\n",
    "        return None\n",
    "    aff_info=colombia[\"affiliations\"].find_one({\"_id\":idx})\n",
    "    name=aff_info[\"names\"][0][\"name\"]\n",
    "    for n in aff_info[\"names\"]:\n",
    "        if n[\"lang\"]==\"es\":\n",
    "            name=n[\"name\"]\n",
    "            break\n",
    "        elif n[\"lang\"]==\"en\":\n",
    "            name=n[\"name\"]\n",
    "    nodes=[idx]\n",
    "    nodes_labels=[name]\n",
    "    edges=[]\n",
    "    edges_coauthorships={}\n",
    "    works_count=0\n",
    "    for work in colombia[\"works\"].find({\"authors.affiliations.id\":idx,\"author_count\":{\"$lte\":10}}):\n",
    "        works_count+=1\n",
    "        work_nodes=[idx]\n",
    "        work_edges=[]\n",
    "        for author in work[\"authors\"]:\n",
    "            for aff in author[\"affiliations\"]:\n",
    "                if not aff[\"id\"]:\n",
    "                    continue\n",
    "                if aff[\"id\"]==\"\":\n",
    "                    continue\n",
    "                if aff[\"id\"]==idx:\n",
    "                    continue\n",
    "                if not aff[\"id\"] in nodes:\n",
    "                    nodes.append(aff[\"id\"])\n",
    "                    #print(author)\n",
    "                    #print(\"-\"*20)\n",
    "                    #print(aff)\n",
    "                    #name=aff[\"names\"][0][\"name\"] # el esquema cambiÃ³\n",
    "                    name=aff[\"name\"]\n",
    "                    \n",
    "                    # for n in aff[\"names\"]: # ya no tiene el idioma, esta parte no sirve\n",
    "                    #     if n[\"lang\"]==\"es\":\n",
    "                    #         name=n[\"name\"]\n",
    "                    #         break\n",
    "                    #     elif n[\"lang\"]==\"en\":\n",
    "                    #         name=n[\"name\"]\n",
    "                    nodes_labels.append(name)\n",
    "                if not aff[\"id\"] in work_nodes:\n",
    "                    for node in work_nodes:\n",
    "                        edge_found=False\n",
    "                        if (idx,aff[\"id\"]) in work_edges:\n",
    "                            edge_found=True\n",
    "                        elif (aff[\"id\"],idx) in edges:\n",
    "                            edge_found=True\n",
    "                        if edge_found==False:\n",
    "                            work_edges.append((idx,aff[\"id\"]))\n",
    "                    work_nodes.append(aff[\"id\"])\n",
    "        #Connecting all the nodes in the work among them\n",
    "        #checking if the connection already exists to add one to the count of coauthorships\n",
    "        for node in work_nodes:\n",
    "            if not node in nodes:\n",
    "                nodes.append(node)\n",
    "        for nodea,nodeb in work_edges:\n",
    "            edge_found=False\n",
    "            if (nodea,nodeb) in edges:\n",
    "                edges_coauthorships[str(nodea)+str(nodeb)]+=1\n",
    "                edge_found=True\n",
    "            elif (nodeb,nodea) in edges:\n",
    "                edges_coauthorships[str(nodeb)+str(nodea)]+=1\n",
    "                edge_found=True\n",
    "            if edge_found==False:\n",
    "                edges_coauthorships[str(nodea)+str(nodeb)]=1\n",
    "                edges.append((nodea,nodeb))\n",
    "    #adding the connections between the coauthoring institutions\n",
    "    for node in nodes:\n",
    "        if node==idx:\n",
    "            continue\n",
    "        for work in colombia[\"works\"].find({\"$and\":[{\"authors.affiliations.id\":node},{\"authors.affiliations.id\":{\"$ne\":idx}}],\"author_count\":{\"$lte\":10}}):\n",
    "            for author in work[\"authors\"]:\n",
    "                for aff in author[\"affiliations\"]:\n",
    "                    if aff[\"id\"]==idx:\n",
    "                        print(\"Problem found\")\n",
    "                        continue\n",
    "                    if not aff[\"id\"] in nodes:\n",
    "                        continue\n",
    "                    if node==aff[\"id\"]:\n",
    "                        continue\n",
    "                    if (node,aff[\"id\"]) in edges:\n",
    "                        edges_coauthorships[str(node)+str(aff[\"id\"])]+=1\n",
    "                    elif (aff[\"id\"],node) in edges:\n",
    "                        edges_coauthorships[str(aff[\"id\"])+str(node)]+=1\n",
    "                    else:\n",
    "                        edges_coauthorships[str(node)+str(aff[\"id\"])]=1\n",
    "                        edges.append((node,aff[\"id\"]))\n",
    "    #Constructing the actual format to insrt in db\n",
    "    num_nodes=len(nodes)\n",
    "    nodes_db=[]\n",
    "    for i,node in enumerate(nodes):\n",
    "        degree=len([1 for i,j in edges if i==node or j==node])\n",
    "        size=50*log(1+degree/(num_nodes-1),2) if num_nodes>1 else 1\n",
    "        nodes_db.append(\n",
    "            {\n",
    "                \"id\":str(node),\n",
    "                \"label\":nodes_labels[i],\n",
    "                \"degree\":degree,\n",
    "                \"size\":size\n",
    "            }\n",
    "        )\n",
    "    edges_db=[]\n",
    "    for nodea,nodeb in edges:\n",
    "        coauthorships=0\n",
    "        if str(nodea)+str(nodeb) in edges_coauthorships.keys():\n",
    "            coauthorships=edges_coauthorships[str(nodea)+str(nodeb)]\n",
    "        elif str(nodeb)+str(nodea) in edges_coauthorships.keys():\n",
    "            coauthorships=edges_coauthorships[str(nodeb)+str(nodea)]\n",
    "        edges_db.append({\n",
    "            \"source\":str(nodea),\n",
    "            \"sourceName\":nodes_labels[nodes.index(nodea)],\n",
    "            \"target\":str(nodeb),\n",
    "            \"targetName\":nodes_labels[nodes.index(nodeb)],\n",
    "            \"coauthorships\":coauthorships,\n",
    "            \"size\":coauthorships,\n",
    "        })\n",
    "    top=max([e[\"coauthorships\"] for e in edges_db]) if len(edges_db)>0 else 1\n",
    "    bot=min([e[\"coauthorships\"] for e in edges_db]) if len(edges_db)>0 else 1\n",
    "    #avg=mean([e[\"coauthorships\"] for e in edges])\n",
    "    for edge in edges_db:\n",
    "        if abs(top-edge[\"coauthorships\"])<0.01:\n",
    "            edge[\"size\"]=10\n",
    "        elif abs(bot-edge[\"coauthorships\"])<0.01:\n",
    "            edge[\"size\"]=1\n",
    "        else:\n",
    "            size=10/(1+exp(6-10*edge[\"coauthorships\"]/top))\n",
    "            edge[\"size\"]=size if size>=1 else 1\n",
    "    impactu[\"affiliations\"].insert_one({\n",
    "        \"_id\":idx,\n",
    "        \"coauthorship_network\":{\n",
    "            \"nodes\":nodes_db,\n",
    "            \"edges\":edges_db\n",
    "        }\n",
    "    })\n",
    "    '''if \"Antioquia\" in nodes_labels[0]:\n",
    "        print(nodes_labels[0],works_count,len(nodes),len(edges))\n",
    "        G=nx.Graph()\n",
    "        G.add_nodes_from(nodes)\n",
    "        G.add_edges_from(edges)\n",
    "        nx.draw(G)'''\n",
    "    #print(nodes_db)\n",
    "    #print(edges_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05eba627-43f3-49e3-962d-ceaa35362cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_creation(institutions_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45195e9a-f357-4f79-8726-39513e6441e5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  12 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Parallel(n_jobs=1,backend=\"multiprocessing\",verbose=10)(delayed(network_creation)(oaid) for oaid in institutions_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148bfadc-39ce-40c7-a332-c7ce28301a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd7224de-2422-43ee-8529-9172e45024b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "#getting the list of institutions ids with works\n",
    "authors_ids=[]\n",
    "for author in colombia[\"person\"].find():\n",
    "    count=colombia[\"works\"].count_documents({\"authors.id\":author[\"_id\"]})\n",
    "    if count!=0:\n",
    "        authors_ids.append(author[\"_id\"])\n",
    "print(len(authors_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78e091d1-3c74-4e83-82d5-f415ca899eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_creation(idx):\n",
    "    already=impactu[\"person\"].find_one({\"_id\":idx})\n",
    "    if already:\n",
    "        return None\n",
    "    aff_info=colombia[\"person\"].find_one({\"_id\":idx})\n",
    "    name=aff_info[\"full_name\"]\n",
    "    nodes=[idx]\n",
    "    nodes_labels=[name]\n",
    "    edges=[]\n",
    "    edges_coauthorships={}\n",
    "    works_count=0\n",
    "    for work in colombia[\"works\"].find({\"authors.id\":idx,\"author_count\":{\"$lte\":10}}):\n",
    "        works_count+=1\n",
    "        work_nodes=[idx]\n",
    "        work_edges=[]\n",
    "        for author in work[\"authors\"]:\n",
    "            if not author[\"id\"]:\n",
    "                continue\n",
    "            if author[\"id\"]==\"\":\n",
    "                continue\n",
    "            if author[\"id\"]==idx:\n",
    "                continue\n",
    "            if not author[\"id\"] in nodes:\n",
    "                nodes.append(author[\"id\"])\n",
    "                name=author[\"full_name\"]\n",
    "                nodes_labels.append(name)\n",
    "            if not author[\"id\"] in work_nodes:\n",
    "                for node in work_nodes:\n",
    "                    edge_found=False\n",
    "                    if (idx,author[\"id\"]) in work_edges:\n",
    "                        edge_found=True\n",
    "                    elif (author[\"id\"],idx) in edges:\n",
    "                        edge_found=True\n",
    "                    if edge_found==False:\n",
    "                        work_edges.append((idx,author[\"id\"]))\n",
    "                work_nodes.append(author[\"id\"])\n",
    "        #Connecting all the nodes in the work among them\n",
    "        #checking if the connection already exists to add one to the count of coauthorships\n",
    "        for node in work_nodes:\n",
    "            if not node in nodes:\n",
    "                nodes.append(node)\n",
    "        for nodea,nodeb in work_edges:\n",
    "            edge_found=False\n",
    "            if (nodea,nodeb) in edges:\n",
    "                edges_coauthorships[str(nodea)+str(nodeb)]+=1\n",
    "                edge_found=True\n",
    "            elif (nodeb,nodea) in edges:\n",
    "                edges_coauthorships[str(nodeb)+str(nodea)]+=1\n",
    "                edge_found=True\n",
    "            if edge_found==False:\n",
    "                edges_coauthorships[str(nodea)+str(nodeb)]=1\n",
    "                edges.append((nodea,nodeb))\n",
    "    #adding the connections between the coauthoring institutions\n",
    "    for node in nodes:\n",
    "        if node==idx:\n",
    "            continue\n",
    "        for work in colombia[\"works\"].find({\"$and\":[{\"authors.id\":node},{\"authors.id\":{\"$ne\":idx}}],\"author_count\":{\"$lte\":10}}):\n",
    "            for author in work[\"authors\"]:\n",
    "                if author[\"id\"]==idx:\n",
    "                    print(\"Problem found\")\n",
    "                    continue\n",
    "                if not author[\"id\"] in nodes:\n",
    "                    continue\n",
    "                if node==author[\"id\"]:\n",
    "                    continue\n",
    "                if (node,author[\"id\"]) in edges:\n",
    "                    edges_coauthorships[str(node)+str(author[\"id\"])]+=1\n",
    "                elif (author[\"id\"],node) in edges:\n",
    "                    edges_coauthorships[str(author[\"id\"])+str(node)]+=1\n",
    "                else:\n",
    "                    edges_coauthorships[str(node)+str(author[\"id\"])]=1\n",
    "                    edges.append((node,author[\"id\"]))\n",
    "    #Constructing the actual format to insrt in db\n",
    "    num_nodes=len(nodes)\n",
    "    nodes_db=[]\n",
    "    for i,node in enumerate(nodes):\n",
    "        degree=len([1 for i,j in edges if i==node or j==node])\n",
    "        size=50*log(1+degree/(num_nodes-1),2) if num_nodes>1 else 1\n",
    "        nodes_db.append(\n",
    "            {\n",
    "                \"id\":str(node),\n",
    "                \"label\":nodes_labels[i],\n",
    "                \"degree\":degree,\n",
    "                \"size\":size\n",
    "            }\n",
    "        )\n",
    "    edges_db=[]\n",
    "    for nodea,nodeb in edges:\n",
    "        coauthorships=0\n",
    "        if str(nodea)+str(nodeb) in edges_coauthorships.keys():\n",
    "            coauthorships=edges_coauthorships[str(nodea)+str(nodeb)]\n",
    "        elif str(nodeb)+str(nodea) in edges_coauthorships.keys():\n",
    "            coauthorships=edges_coauthorships[str(nodeb)+str(nodea)]\n",
    "        edges_db.append({\n",
    "            \"source\":str(nodea),\n",
    "            \"sourceName\":nodes_labels[nodes.index(nodea)],\n",
    "            \"target\":str(nodeb),\n",
    "            \"targetName\":nodes_labels[nodes.index(nodeb)],\n",
    "            \"coauthorships\":coauthorships,\n",
    "            \"size\":coauthorships,\n",
    "        })\n",
    "    top=max([e[\"coauthorships\"] for e in edges_db]) if len(edges_db)>0 else 1\n",
    "    bot=min([e[\"coauthorships\"] for e in edges_db]) if len(edges_db)>0 else 1\n",
    "    #avg=mean([e[\"coauthorships\"] for e in edges])\n",
    "    for edge in edges_db:\n",
    "        if abs(top-edge[\"coauthorships\"])<0.01:\n",
    "            edge[\"size\"]=10\n",
    "        elif abs(bot-edge[\"coauthorships\"])<0.01:\n",
    "            edge[\"size\"]=1\n",
    "        else:\n",
    "            size=10/(1+exp(6-10*edge[\"coauthorships\"]/top))\n",
    "            edge[\"size\"]=size if size>=1 else 1\n",
    "    impactu[\"person\"].insert_one({\n",
    "        \"_id\":idx,\n",
    "        \"coauthorship_network\":{\n",
    "            \"nodes\":nodes_db,\n",
    "            \"edges\":edges_db\n",
    "        }\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e580d202-9e75-476d-a743-10895d6bc16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_creation(authors_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0708698c-406a-4764-b283-9458ad78aecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Parallel(n_jobs=20,backend=\"multiprocessing\",verbose=10)(delayed(network_creation)(oaid) for oaid in authors_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1dbfa2-5018-4309-a71b-d8d3cd821338",
   "metadata": {},
   "source": [
    "### Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88bfe1bd-005e-4cf6-9c7f-c863046c1a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in ./.local/lib/python3.11/site-packages (from en-core-web-sm==3.7.1) (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in ./.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in ./.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in ./.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in ./.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.3)\n",
      "Requirement already satisfied: jinja2 in ./.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\n",
      "Requirement already satisfied: setuptools in ./.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in ./.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.24.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.local/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in ./.local/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.14.6)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./.local/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.local/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.local/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.local/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.local/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in ./.local/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./.local/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in ./.local/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in ./.local/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.local/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.3)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.7.1\n",
      "\u001b[38;5;2mâ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48f40599-7004-4dfd-993d-b8908b261078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting es-core-news-sm==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.7.0/es_core_news_sm-3.7.0-py3-none-any.whl (12.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in ./.local/lib/python3.11/site-packages (from es-core-news-sm==3.7.0) (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in ./.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.2.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in ./.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in ./.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in ./.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.66.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.5.3)\n",
      "Requirement already satisfied: jinja2 in ./.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in ./.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in ./.local/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.24.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.local/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in ./.local/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.14.6)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./.local/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.local/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.local/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.local/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.local/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in ./.local/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./.local/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in ./.local/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in ./.local/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.local/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.1.3)\n",
      "Installing collected packages: es-core-news-sm\n",
      "Successfully installed es-core-news-sm-3.7.0\n",
      "\u001b[38;5;2mâ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('es_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python -m spacy download es_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043fbcd1-bd59-4e9e-b079-2e1676989efe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71711c25-f6e5-4824-ad73-e0847d69ef26",
   "metadata": {},
   "outputs": [],
   "source": [
    "en = spacy.load('en_core_web_sm')\n",
    "es = spacy.load('es_core_news_sm')\n",
    "stopwords = en.Defaults.stop_words.union(es.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85a7eb92-8953-4c97-9115-09e68fafef0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#esto inserta top_words en la affiliations\n",
    "#top_words: [\n",
    "  #   { name: 'bind', value: 2 },\n",
    "  #   { name: 'state', value: 2 },\n",
    "  #   { name: 'dark', value: 2 },\n",
    "  #   { name: 'matter', value: 2 },\n",
    "  #   { name: 'dirac', value: 1 },\n",
    "  #   { name: 'neutrino', value: 1 },\n",
    "  #   { name: 'masse', value: 1 },\n",
    "  #   { name: 'majorana', value: 1 },\n",
    "  #   { name: 'neutrinos', value: 1 }\n",
    "  # ]\n",
    "#Podria hacer una funiciÃ³n que se llame top_words\n",
    "for aff in colombia[\"affiliations\"].find():\n",
    "    aff_db=impactu[\"affiliations\"].find_one({\"_id\":aff[\"_id\"],\"top_words\":{\"$exists\":1}})\n",
    "    if aff_db:\n",
    "        continue\n",
    "    results={}\n",
    "    for work in colombia[\"works\"].find({\"authors.affiliations.id\":aff[\"_id\"],\"titles\":{\"$exists\":1}},{\"titles\":1}):\n",
    "        title=work[\"titles\"][0][\"title\"].lower()\n",
    "        lang=work[\"titles\"][0][\"lang\"]\n",
    "        if lang==\"es\":\n",
    "            model=es\n",
    "        else:\n",
    "            model=en\n",
    "        title=model(title)\n",
    "        for token in title:\n",
    "            if token.lemma_.isnumeric():\n",
    "                continue\n",
    "            if token.lemma_ in stopwords:\n",
    "                continue\n",
    "            if len(token.lemma_)<4:\n",
    "                continue\n",
    "            if token.lemma_ in results.keys():\n",
    "                results[token.lemma_]+=1\n",
    "            else:\n",
    "                results[token.lemma_]=1\n",
    "    topN=sorted(results.items(), key=lambda x: x[1], reverse=True)[:20]\n",
    "    results=[]\n",
    "    for top in topN:\n",
    "        results.append({\"name\":top[0],\"value\":top[1]})\n",
    "    aff_db=impactu[\"affiliations\"].find_one({\"_id\":aff[\"_id\"]})\n",
    "    if aff_db:\n",
    "        impactu[\"affiliations\"].update_one({\"_id\":aff[\"_id\"]},{\"$set\":{\"top_words\":results}})\n",
    "    else:\n",
    "        impactu[\"affiliations\"].insert_one({\"_id\":aff[\"_id\"],\"top_words\":results})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8642439-2cc3-44c5-aae3-3744761fb7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#affiliations other tha institutions\n",
    "for aff in colombia[\"affiliations\"].find({\"types.type\":{\"$in\":[\"faculty\",\"department\",\"group\"]}}):\n",
    "    aff_db=impactu[\"affiliations\"].find_one({\"_id\":aff[\"_id\"],\"top_words\":{\"$exists\":1}})\n",
    "    if aff_db:\n",
    "        results={}\n",
    "        for author in colombia[\"person\"].find({\"affiliations.id\":aff[\"_id\"]}):\n",
    "            for work in colombia[\"works\"].find({\"authors.id\":author[\"_id\"]}):\n",
    "                title=work[\"titles\"][0][\"title\"].lower()\n",
    "                lang=work[\"titles\"][0][\"lang\"]\n",
    "                if lang==\"es\":\n",
    "                    model=es\n",
    "                else:\n",
    "                    model=en\n",
    "                title=model(title)\n",
    "                for token in title:\n",
    "                    if token.lemma_.isnumeric():\n",
    "                        continue\n",
    "                    if token.lemma_ in stopwords:\n",
    "                        continue\n",
    "                    if len(token.lemma_)<4:\n",
    "                        continue\n",
    "                    if token.lemma_ in results.keys():\n",
    "                        results[token.lemma_]+=1\n",
    "                    else:\n",
    "                        results[token.lemma_]=1\n",
    "        topN=sorted(results.items(), key=lambda x: x[1], reverse=True)[:20]\n",
    "        results=[]\n",
    "        for top in topN:\n",
    "            results.append({\"name\":top[0],\"value\":top[1]})\n",
    "        impactu[\"affiliations\"].update_one({\"_id\":aff[\"_id\"]},{\"$set\":{\"top_words\":results}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "56942773-9a08-4767-950b-3bd1486e21b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_inserted_ids=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105523ce-fa8a-49c8-bd56-4fa4e449c7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with client.start_session() as session:\n",
    "    old=dt.datetime.now()\n",
    "    for aff in colombia[\"person\"].find({\"_id\":{\"$nin\":words_inserted_ids}}):\n",
    "        aff_db=impactu[\"person\"].find_one({\"_id\":aff[\"_id\"],\"top_words\":{\"$exists\":1}})\n",
    "        if aff_db:\n",
    "            words_inserted_ids.append(aff[\"_id\"])\n",
    "            continue\n",
    "        results={}\n",
    "        for work in colombia[\"works\"].find({\"authors.id\":aff[\"_id\"],\"titles\":{\"$exists\":1}},{\"titles\":1}):\n",
    "            title=work[\"titles\"][0][\"title\"].lower()\n",
    "            lang=work[\"titles\"][0][\"lang\"]\n",
    "            if lang==\"es\":\n",
    "                model=es\n",
    "            else:\n",
    "                model=en\n",
    "            title=model(title)\n",
    "            for token in title:\n",
    "                if token.lemma_.isnumeric():\n",
    "                    continue\n",
    "                if token.lemma_ in stopwords:\n",
    "                    continue\n",
    "                if len(token.lemma_)<4:\n",
    "                    continue\n",
    "                if token.lemma_ in results.keys():\n",
    "                    results[token.lemma_]+=1\n",
    "                else:\n",
    "                    results[token.lemma_]=1\n",
    "        topN=sorted(results.items(), key=lambda x: x[1], reverse=True)[:20]\n",
    "        results=[]\n",
    "        for top in topN:\n",
    "            results.append({\"name\":top[0],\"value\":top[1]})\n",
    "        aff_db=impactu[\"person\"].find_one({\"_id\":aff[\"_id\"]})\n",
    "        if aff_db:\n",
    "            impactu[\"person\"].update_one({\"_id\":aff[\"_id\"]},{\"$set\":{\"top_words\":results}})\n",
    "        else:\n",
    "            impactu[\"person\"].insert_one({\"_id\":aff[\"_id\"],\"top_words\":results})\n",
    "            \n",
    "        delta=dt.datetime.now()-old\n",
    "        if delta.seconds>240:\n",
    "            client.admin.command('refreshSessions', [session.session_id], session=session)\n",
    "            old=dt.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9dcd6064-28c2-4022-9fc0-9114dd9ba065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids=[ObjectId(\"63935abf71459ce0bcb933a8\")]\n",
    "for aff in ids:\n",
    "    sum_docs=0\n",
    "    for author in colombia[\"person\"].find({\"affiliations\":aff}):\n",
    "        sum_docs+=colombia[\"person\"].count_documents({\"authors.id\":author[\"_id\"]})\n",
    "sum_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dfa159-f15c-4268-a821-ff82ada7075e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
